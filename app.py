import streamlit as st
from google import genai
import datetime

# 1. é¡µé¢é…ç½®
st.set_page_config(page_title="AI æé—®å·¥ä½œç«™", page_icon="ğŸ› ï¸", layout="wide")

# 2. åˆå§‹åŒ–çŠ¶æ€
if 'chat_log' not in st.session_state: st.session_state.chat_log = []
if 'usage_count' not in st.session_state: st.session_state.usage_count = 0

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.title("âš™ï¸ é…ç½®ä¸­å¿ƒ")
    api_key = st.text_input("Gemini API Key", type="password")
    model_name = st.selectbox("é€‰æ‹©æ¨¡å‹", ["gemini-2.0-flash", "gemini-2.5-pro"])
    st.divider()
    st.metric("å·²æ¶ˆè€—è¯·æ±‚", st.session_state.usage_count)
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰è®°å½•"):
        st.session_state.chat_log = []
        st.session_state.usage_count = 0
        st.rerun()

# --- ä¸»ç•Œé¢ï¼šæ¨¡å—åŒ–æ ‡ç­¾é¡µ ---
tab1, tab2, tab3 = st.tabs(["ğŸ¤ æ‹‰å¼å¯¹è¯è¯Šæ–­", "ğŸ­ é€šç”¨æç¤ºè¯å·¥å‚", "ğŸ¯ æ‹‰å¼æŒ‡ä»¤åˆæˆ"])

# --- æ¨¡å—ä¸€ï¼šæ‹‰å¼å¯¹è¯è¯Šæ–­ ---
with tab1:
    st.subheader("æ‹‰å¼æé—®ï¼šä¸ AI æ·±åº¦ç£¨åˆ")
    if not st.session_state.chat_log:
        with st.form("init_form"):
            f1, f2 = st.columns(2)
            field = f1.text_input("ä¸“ä¸šé¢†åŸŸ", value="å‰¯ä¸šè½¬å‹")
            goal = f2.text_input("æœ€ç»ˆç›®æ ‡", value="å¯»æ‰¾é€‚åˆçš„å‰¯ä¸šé¡¹ç›®")
            status = st.text_area("ç°çŠ¶æè¿°", placeholder="æè¿°ä½ çš„èƒŒæ™¯...")
            limits = st.text_area("é™åˆ¶æ¡ä»¶", placeholder="é¢„ç®—ã€æ—¶é—´ç­‰...")
            if st.form_submit_button("ğŸ¯ å¼€å§‹è¯Šæ–­"):
                if api_key:
                    prompt = f"é¢†åŸŸï¼š{field}\nç›®æ ‡ï¼š{goal}\nç°çŠ¶ï¼š{status}\né™åˆ¶ï¼š{limits}"
                    st.session_state.chat_log.append({"role": "user", "content": prompt})
                    st.session_state.needs_reply = True
                    st.rerun()
                else: st.error("è¯·åœ¨ä¾§è¾¹æ å¡«å…¥ Key")

    for msg in st.session_state.chat_log:
        with st.chat_message(msg["role"]): st.markdown(msg["content"])

    if st.session_state.get('needs_reply'):
        try:
            client = genai.Client(api_key=api_key)
            res = client.models.generate_content(model=model_name, contents=st.session_state.chat_log[-1]["content"], 
                  config={"system_instruction": "ä½ æ˜¯ä¸€ä¸ªæ‹‰å¼æé—®ä¸“å®¶ï¼Œè´Ÿè´£é€šè¿‡è¿½é—®æŒ–æ˜ç›²ç‚¹ã€‚"})
            st.session_state.chat_log.append({"role": "assistant", "content": res.text})
            st.session_state.usage_count += 1
            del st.session_state.needs_reply
            st.rerun()
        except Exception as e: st.error(f"è¿æ¥å¤±è´¥: {e}")

    if st.session_state.chat_log and not st.session_state.get('needs_reply'):
        if u_input := st.chat_input("å›ç­”é—®é¢˜æˆ–è¿½é—®..."):
            st.session_state.chat_log.append({"role": "user", "content": u_input})
            st.session_state.needs_reply = True
            st.rerun()

# --- æ¨¡å—äºŒï¼šé€šç”¨æç¤ºè¯å·¥å‚ ---
with tab2:
    st.subheader("ç»“æ„åŒ– Prompt ç”Ÿæˆ")
    with st.container(border=True):
        role_p = st.text_input("AI è§’è‰²", placeholder="èµ„æ·±è¥é”€ä¸“å®¶")
        task_p = st.text_area("æ‰§è¡Œä»»åŠ¡", placeholder="å†™ä¸€ä»½äº§å“å‘å¸ƒç¨¿")
        rule_p = st.text_area("å…·ä½“è¦æ±‚", placeholder="é£æ ¼å¹½é»˜ã€å¸¦æ•°æ®...")
        if st.button("ğŸª„ ç”Ÿæˆé€šç”¨æç¤ºè¯"):
            res_p = f"# Role: {role_p}\n## Task: {task_p}\n## Rules: \n{rule_p}"
            st.code(res_p, language="markdown")

# --- æ¨¡å—ä¸‰ï¼šæ‹‰å¼æŒ‡ä»¤åˆæˆ (New!) ---
with tab3:
    st.subheader("æ‹‰å¼æç¤ºè¯ (Pull-Mode) ä¸“ç”¨ç”Ÿæˆå™¨")
    st.markdown("æƒ³è¦è®©å…¶ä»– AI ä¹Ÿèƒ½åƒè¿™ä¸ªå·¥å…·ä¸€æ ·â€˜å®¡é—®â€™ä½ å—ï¼Ÿåœ¨è¿™é‡Œç”Ÿæˆä¸“å±æŒ‡ä»¤ã€‚")
    
    with st.container(border=True):
        p_expert = st.text_input("æƒ³è¦å‘¼å”¤å“ªæ–¹é¢çš„ä¸“å®¶ï¼Ÿ", value="å•†ä¸šæˆ˜ç•¥å’¨è¯¢é¡¾é—®")
        p_intent = st.text_area("ä½ å‡†å¤‡èŠä»€ä¹ˆè¯é¢˜ï¼Ÿ", placeholder="ä¾‹å¦‚ï¼šæˆ‘æƒ³åœ¨42å²è½¬å‹åšçº¿ä¸Šæ•™è‚²...")
        p_count = st.slider("æ¯è½®æé—®æ•°é‡", 1, 10, 5)
        
        if st.button("ğŸ”¥ ç”Ÿæˆæ‹‰å¼æé—®ä¸“å± Prompt"):
            pull_prompt = f"""ä½ ç°åœ¨æ˜¯ä¸€ä½æ‹¥æœ‰20å¹´ç»éªŒçš„ã€{p_expert}ã€‘ã€‚

## èƒŒæ™¯ä¸æ„å›¾ï¼š
{p_intent}

## ä½ çš„ä»»åŠ¡ï¼ˆå¯åŠ¨æ‹‰å¼åä½œèŒƒå¼ï¼‰ï¼š
1. è¯·å…ˆä¸è¦ç›´æ¥ç»™æˆ‘å»ºè®®æˆ–ç­”æ¡ˆã€‚
2. è¯·åŸºäºä½ çš„ä¸“ä¸šè§†è§’ï¼ŒæŒ‡å‡ºæˆ‘åœ¨æè¿°è¿™ä¸ªæ„å›¾æ—¶å¯èƒ½å­˜åœ¨çš„ã€è®¤çŸ¥ç›²åŒºã€‘ã€‚
3. è¯·å‘æˆ‘æå‡º {p_count} ä¸ªå…³é”®é—®é¢˜ã€‚è¿™äº›é—®é¢˜åº”å½“èƒ½å¸®åŠ©ä½ è·å–ç»™å‡ºâ€œå®¢è§‚æœ€ä¼˜è§£â€æ‰€éœ€çš„æ·±åº¦ä¿¡æ¯ã€‚
4. åœ¨æˆ‘å›ç­”è¿™äº›é—®é¢˜åï¼Œè¯·å†ä¸ºæˆ‘æä¾›ä¸€ä¸ªç³»ç»Ÿæ€§çš„è§£å†³æ–¹æ¡ˆã€‚

è¯·å¼€å§‹ç¬¬ä¸€æ­¥ï¼šåˆ†æç›²åŒºå¹¶æé—®ã€‚"""
            
            st.success("ç”Ÿæˆçš„æ‹‰å¼æŒ‡ä»¤å·²å°±ç»ªï¼š")
            st.code(pull_prompt, language="markdown")
            st.info("ğŸ’¡ ä½¿ç”¨æ–¹æ³•ï¼šå¤åˆ¶ä¸Šæ–¹ä»£ç å—ï¼Œç›´æ¥å‘é€ç»™ ChatGPTã€Claude æˆ– DeepSeekã€‚")